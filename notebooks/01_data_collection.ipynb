{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3513cde2-29d4-4688-b29d-200afbfd13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/openai/whisper.git\n",
    "# ! pip install pytube\n",
    "# ! pip install pypdf langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f44e2c-9a64-4386-a636-5ddaed26e22b",
   "metadata": {},
   "source": [
    "## 1. Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "13ea1811-93b7-4c00-b08e-f3f210d14a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d3bf68fa-9ae1-46f8-af59-66273e4f0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inspire_hep_papers(author):\n",
    "    inspire_url = \"https://inspirehep.net/api/literature\"\n",
    "    params = {\n",
    "        \"q\": f\"author:{author}\",\n",
    "        \"size\": 1000,  # Increase this value if the author has more than 1000 papers\n",
    "        \"fields\": \"arxiv_eprints\",\n",
    "    }\n",
    "    response = requests.get(inspire_url, params=params)\n",
    "    data = response.json()\n",
    "    papers = data[\"hits\"][\"hits\"]\n",
    "    return papers\n",
    "\n",
    "def extract_arxiv_ids(papers):\n",
    "    arxiv_ids = []\n",
    "    for paper in papers:\n",
    "        arxiv_eprints = paper['metadata'].get(\"arxiv_eprints\", [])\n",
    "        if arxiv_eprints:\n",
    "            arxiv_id = arxiv_eprints[0][\"value\"]\n",
    "            arxiv_ids.append(arxiv_id)\n",
    "    return arxiv_ids\n",
    "\n",
    "def download_arxiv_pdf(arxiv_id, output_dir=\"../data/pdfs\"):\n",
    "    pdf_url = f\"https://arxiv.org/pdf/{arxiv_id}.pdf\"\n",
    "    response = requests.get(pdf_url)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{arxiv_id}.pdf\".replace(\"/\", \"_\"))\n",
    "\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        \n",
    "def get_pdf_filenames(directory):\n",
    "    all_files = os.listdir(directory)\n",
    "    pdf_files = [file for file in all_files if file.lower().endswith('.pdf')]\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1147bcaf-6167-47ba-b12f-49c83aed50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = '../data/pdfs/'\n",
    "\n",
    "papers = get_inspire_hep_papers(\"Jesse.Thaler.1\")\n",
    "arxiv_ids = extract_arxiv_ids(papers)\n",
    "[download_arxiv_pdf(arxiv_id) for arxiv_id in tqdm(arxiv_ids)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0ff08afe-449a-4f4d-abbc-5444c6da6f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 142/142 [05:40<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "source_type = []\n",
    "source_location = []\n",
    "text = []\n",
    "\n",
    "for i, file in enumerate(tqdm(get_pdf_filenames(pdf_dir))):\n",
    "    loader = PyPDFLoader(\"{}/{}\".format(pdf_dir, file))\n",
    "    pages = loader.load_and_split()\n",
    "    \n",
    "    text.append(''.join([page.page_content for page in pages]))\n",
    "    source_type.append(\"paper\")\n",
    "    source_location.append(\"https://arxiv.org/abs/{}\".format(file.replace('_', '/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4e2cf145-2efe-47ae-b0ae-f46450ce4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [source_type, source_location, text]\n",
    "\n",
    "# Transpose the data to have the inner lists as rows\n",
    "transposed_data = list(map(list, zip(*data)))\n",
    "\n",
    "# Column names for the DataFrame\n",
    "columns = ['source_type', 'source_location', 'text']\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(transposed_data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4a1adee0-cab0-40c4-b4d9-370a327de4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/text/df_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b2865-d315-41b1-9c26-531dc2301412",
   "metadata": {},
   "source": [
    "## 2. YouTube videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741ca70-fb4d-4aca-ac61-49359e39aae4",
   "metadata": {},
   "source": [
    "## 3. Interviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb533fd8-f08d-4c00-8d35-d1b28da4552d",
   "metadata": {},
   "source": [
    "## 4. Articles/Websites/CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a982fa31-d5ed-437d-b96c-f04e422ed4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import whisper\n",
    "import pytube\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "047261b5-9d87-493c-941f-2c84237f4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"tiny.en\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e04d17-904e-4536-bfe4-6fd02859c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b5b800-9a63-48ff-847d-c3e55e670a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/holystore01/LABS/iaifi_lab/Users/smsharma/jesse-embedding/notebooks/dqxdPNzBY0I.mp4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=dqxdPNzBY0I\"\n",
    "pytube_vid = pytube.YouTube(url)\n",
    "\n",
    "video_path_local = Path(\".\").resolve() / (pytube_vid.video_id+\".mp4\")\n",
    "pytube_vid.streams.filter(type=\"audio\", mime_type=\"audio/mp4\", abr=\"48kbps\").first().download(output_path=video_path_local.parent, filename=video_path_local.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d33c292f-638f-46d7-93e4-72e062f9331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path_local = video_path_local.with_suffix(\".wav\")\n",
    "result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "533fcfac-a994-4622-8038-cd64cf3f456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = whisper.transcribe(whisper_model, str(video_path_local))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "302f0b18-3cba-40bb-8a85-3951bdd90189",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6fb7e56c-1fff-477e-aead-9e5352b72077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(text, window_size, stride):\n",
    "    tokens = text.split()\n",
    "    window_start = 0\n",
    "    while window_start < len(tokens):\n",
    "        window_end = min(window_start + window_size, len(tokens))\n",
    "        yield ' '.join(tokens[window_start:window_end])\n",
    "        window_start += stride\n",
    "        \n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "\n",
    "def semantic_search(query_embedding, embeddings):\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
    "    ranked_indices = np.argsort(-similarities)\n",
    "    return ranked_indices\n",
    "\n",
    "def answer_question(chunk, question, model=\"text-davinci-002\", max_tokens=150, temperature=0.7):\n",
    "    prompt = f\"{chunk}\\nQuestion: {question}\\nAnswer:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].text.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "884967fe-666f-44df-8f27-a59606814cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2da5b706e24363844e976b0e1bcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "window_size = 1024\n",
    "stride = 512\n",
    "\n",
    "text_chunks = list(sliding_window(transcription['text'], window_size, stride))\n",
    "emeddings = [get_embedding(text) for text in tqdm(text_chunks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "132b048f-bfb2-4087-9d98-6edbe26396ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"will real time decision making be relevant for the LHC? what other experiments will it be relevant for?\"\n",
    "query_embedding = get_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c23d3c15-5702-46d9-8c41-edb43514d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_indices = semantic_search(np.array(query_embedding), np.array(emeddings))\n",
    "most_relevant_chunk = text_chunks[ranked_indices[0]]\n",
    "answer = answer_question(most_relevant_chunk, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5dcf85de-49ea-4469-bb0b-2657fe6b31b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real-time decision making may be relevant for the LHC in the context of triggering. Triggering is the process of deciding which collisions to save and which to discard. It may also be relevant for other experiments, such as LIGO, which is looking at how to control their gravitational wave observations.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
